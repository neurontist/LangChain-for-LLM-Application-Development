{
  "cells": [
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neurontist/LangChain-for-LLM-Application-Development/blob/main/L1%20Models%20Prompts%20and%20Parsers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain: Models, Prompts and Output Parsers\n",
        "Outline\n",
        "* Direct API calls to OpenAI\n",
        "* API calls through LangChain:\n",
        "* Prompts\n",
        "* Models\n",
        "* Output parsers"
      ],
      "metadata": {
        "id": "0RCRdDyHiPNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Langchain"
      ],
      "metadata": {
        "id": "C9o8qKqon-0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "dRJ2v0LSnZUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "id": "atkbxgDJgEON",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the API Key"
      ],
      "metadata": {
        "id": "-olM9OoyneL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "DM9-Rfa6gGIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "MCUOF54Sni1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = \"gemini-1.5-flash\""
      ],
      "metadata": {
        "id": "YgJqWp4QhPmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Content using generate_content()"
      ],
      "metadata": {
        "id": "lEWUt9G7nrIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=llm_model):\n",
        "    response = genai.GenerativeModel(model).generate_content(\n",
        "          prompt,\n",
        "          generation_config={\n",
        "              \"temperature\": 0.0\n",
        "          }\n",
        "      )\n",
        "    return response.text\n",
        "\n",
        "get_completion(\"What is capital of India?\")"
      ],
      "metadata": {
        "id": "vth6TbP9iLrg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53f522ef-f68a-4609-e3d1-c2e57b64907e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of India is **New Delhi**.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "brNKJwvmn24L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_email = \"\"\"\n",
        "Arrr, I be fuming that me blender lid \\\n",
        "flew off and splattered me kitchen walls \\\n",
        "with smoothie! And to make matters worse,\\\n",
        "the warranty don't cover the cost of \\\n",
        "cleaning up me kitchen. I need yer help \\\n",
        "right now, matey!\n",
        "\"\"\"\n",
        "\n",
        "style = \"\"\"American English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ATgJ0ihkiPUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Translate the text \\\n",
        "that is delimited by triple backticks\n",
        "into a style that is {style}.\n",
        "text: ```{customer_email}```\n",
        "\"\"\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "nCOnjqq6iKxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881cfffd-dce3-4e8f-8a8d-502f957f9bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate the text that is delimited by triple backticks\n",
            "into a style that is American English in a calm and respectful tone\n",
            ".\n",
            "text: ```\n",
            "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Response"
      ],
      "metadata": {
        "id": "UUTMiED0n6y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "ON8pomAbjGs8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "05ccf8c0-6232-414b-f92f-9d36873ae474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm quite upset that my blender lid came off unexpectedly, resulting in smoothie splattered on my kitchen walls.  To make matters worse, the warranty doesn't appear to cover the cost of cleaning up the mess. I would appreciate your assistance with this matter.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Langchain"
      ],
      "metadata": {
        "id": "aVQDQdKZjOVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain"
      ],
      "metadata": {
        "id": "PFWmCv3sjNHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import API Key"
      ],
      "metadata": {
        "id": "ekk0TS84o-rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "gv0AEZyRooyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using ChatGoogleGenerativeAI()"
      ],
      "metadata": {
        "id": "99-l_zp9pCIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "8UfGRM60jWhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatGoogleGenerativeAI(model=llm_model,temperature=0.6,api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "A2gVqs0rm0Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a prompt\n",
        "\n",
        "Variable/Input is passed to the prompt inside curly brackets, like python f-string"
      ],
      "metadata": {
        "id": "gX6QY9gPpOW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XMt3mZROjyd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting the prompt to Langchain Prompt Template to work with"
      ],
      "metadata": {
        "id": "siApDu_TpjNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "EYpO590zj1qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_style = \"\"\"American English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\"\n",
        "\n",
        "customer_email = \"\"\"\n",
        "Arrr, I be fuming that me blender lid \\\n",
        "flew off and splattered me kitchen walls \\\n",
        "with smoothie! And to make matters worse, \\\n",
        "the warranty don't cover the cost of \\\n",
        "cleaning up me kitchen. I need yer help \\\n",
        "right now, matey!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YpZ8oWeGm-vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passing the input variables to the prompt template"
      ],
      "metadata": {
        "id": "hLoPKkXXpwH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_messages = prompt_template.format_messages(\n",
        "    style=customer_style,\n",
        "    text = customer_email\n",
        ")"
      ],
      "metadata": {
        "id": "vSRxm0pEnDrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the response"
      ],
      "metadata": {
        "id": "LD4D--ywp2U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_response = chat(customer_messages)\n",
        "\n",
        "customer_response.content"
      ],
      "metadata": {
        "id": "SUlxerWSnQBk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "8304cd2f-cb7f-4bab-840e-1f5212f3f72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-801e952fdba5>:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  customer_response = chat(customer_messages)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm quite upset that my blender lid came off unexpectedly, and smoothie splattered on my kitchen walls.  To add to my frustration, the warranty doesn't cover the cost of cleaning up the mess. I would appreciate your assistance with this matter.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output Parsers"
      ],
      "metadata": {
        "id": "VASuZ-KsqZBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n"
      ],
      "metadata": {
        "id": "XfLUL5z1sqsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Dictionary"
      ],
      "metadata": {
        "id": "CnWskDvEqcpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"gift\": False,\n",
        "  \"delivery_days\": 5,\n",
        "  \"price_value\": \"pretty affordable!\"\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8oBSxnrqbqg",
        "outputId": "ff943675-01a6-4c02-931d-534137ea2bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customer template and the review template"
      ],
      "metadata": {
        "id": "Qiekj0ymqgpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_review = \"\"\"\\\n",
        "This leaf blower is pretty amazing.  It has four settings:\\\n",
        "candle blower, gentle breeze, windy city, and tornado. \\\n",
        "It arrived in two days, just in time for my wife's \\\n",
        "anniversary present. \\\n",
        "I think my wife liked it so much she was speechless. \\\n",
        "So far I've been the only one using it, and I've been \\\n",
        "using it every other morning to clear the leaves on our lawn. \\\n",
        "It's slightly more expensive than the other leaf blowers \\\n",
        "out there, but I think it's worth it for the extra features.\n",
        "\"\"\"\n",
        "\n",
        "review_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zPJQN-0urBTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the response"
      ],
      "metadata": {
        "id": "Cc4D1kTEqqlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "promt_template = ChatPromptTemplate.from_template(review_template)"
      ],
      "metadata": {
        "id": "3oMz5aEPqg1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = prompt_template.format_messages(text=customer_review,style=None)\n",
        "\n",
        "chat = ChatGoogleGenerativeAI(temperature=0.0, model=llm_model,api_key=GOOGLE_API_KEY)\n",
        "\n",
        "response = chat(messages)\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "3EzOxkV-rAxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a566b5-a328-4b60-c95b-c57a93e7051c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This leaf blower is pretty amazing.  It has four settings: candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(response.content)"
      ],
      "metadata": {
        "id": "OXJvYv10r_6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67144fd4-4501-4712-89d7-b9b0a79a3801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# response.content.get('gift')"
      ],
      "metadata": {
        "id": "nfZQ79tisEhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code line shows that the text generated by LLM is just a string and not a dictionary, we need to parse the output to achieve the result"
      ],
      "metadata": {
        "id": "ZL9a_RllqvA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse the LLM output string into a Python dictionary\n",
        "\n",
        "For this we need ResponseSchema and StructuredOutputParser from langchain parser"
      ],
      "metadata": {
        "id": "nHXbAU6HscKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
      ],
      "metadata": {
        "id": "0Yj-LPDMskvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turn the desired output vaules we are going to recieve into schemas and make a list"
      ],
      "metadata": {
        "id": "s_uTTr4MrSvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gift_schema = ResponseSchema(name=\"gift\",\n",
        "                             description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\")\n",
        "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
        "                                      description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\")\n",
        "price_value_schema = ResponseSchema(name=\"price_value\",\n",
        "                                    description=\"Extract any sentences about the value or price, and output them as a comma separated Python list.\")\n",
        "\n",
        "response_schemas = [gift_schema,\n",
        "                    delivery_days_schema,\n",
        "                    price_value_schema]"
      ],
      "metadata": {
        "id": "xe1g9WplsuXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Call the StructuredOutputParser"
      ],
      "metadata": {
        "id": "yyVgRh2Mrix8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "format_instructions = output.get_format_instructions()"
      ],
      "metadata": {
        "id": "Myor6K9ws6eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Prompt Template and pass the formatted Instructions"
      ],
      "metadata": {
        "id": "glVkD3gJryKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_template_2 = \"\"\"\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else?\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "text: {text}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AAIHrUI0tmbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
        "\n",
        "messages = prompt.format_messages(text=customer_review,\n",
        "                                format_instructions=format_instructions)"
      ],
      "metadata": {
        "id": "ucVSfCGdtpp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat(messages)"
      ],
      "metadata": {
        "id": "o22ZtsqxtsoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Call the variable which contains our StructuredOutputParser to parse the response generated"
      ],
      "metadata": {
        "id": "hg4zHd_5sNdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict = output.parse(response.content)"
      ],
      "metadata": {
        "id": "F9khooHSt4HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict"
      ],
      "metadata": {
        "id": "wamNhrxcu_dW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db4b2d8-17e9-477b-cd41-0291973341df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gift': 'True',\n",
              " 'delivery_days': '2',\n",
              " 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict.get('gift')"
      ],
      "metadata": {
        "id": "AuM1PN2FvAqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fdd8cbe1-ecd4-478f-9d26-0a6d359ee76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'True'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Another Example of Output Parsing for practice"
      ],
      "metadata": {
        "id": "BIJ8fsDWPz19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "email_response = \"\"\"\n",
        "Here's our itinerary for our upcoming trip to Europe.\n",
        "We leave from Denver, Colorado airport at 8:45 pm, and arrive in Amsterdam 10 hours\n",
        "later at Schipol Airport.\n",
        "We'll grab a ride to our Airbnb and maybe stop somewhere for breakfast before\n",
        "taking a nap.\n",
        "\n",
        "Some sightseeing will follow for a couple of hours.\n",
        "We will then go shop for gifts\n",
        "to bring back to our children and friends.\n",
        "\n",
        "The next morning, at 7:45 am we'll drive to Belgium, Brussels – it should only take\n",
        "a couple of hours. While in Brussels, we want to explore the city to its fullest – no rock left unturned.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Deykm41FHAKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_template = \"\"\"\n",
        "From the following email, extract the following information:\n",
        "\n",
        "leave_time: when are they leaving for vacation to Europe. If there's an actual\n",
        "time written, use it, if not write unknown.\n",
        "\n",
        "leave_from: where are they leaving from, the airport or city name and state if\n",
        "available.\n",
        "\n",
        "cities_to_visit: extract the cities they are going to visit. If there are more than\n",
        "one, put them in square brackets like [\"cityone\", \"citytwo\"].\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "leave_time\n",
        "leave_from\n",
        "cities_to_visit\n",
        "\n",
        "email: {email}\n",
        "{format_instructions}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "POCajKvyJNPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "R_BEFu5JJOUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leave_time_schema = ResponseSchema(\n",
        "    name=\"leave_time\",\n",
        "    description=\"when are they leaving for vacation to Europe. If there's an actual \\\n",
        "    time written, use it, if not write unknown.\"\n",
        ")\n",
        "leave_from_schema = ResponseSchema(\n",
        "    name=\"leave_from\",\n",
        "    description=\"where are they leaving from, the airport or city name and state if \\\n",
        "    available.\"\n",
        ")\n",
        "cities_to_visit_schema = ResponseSchema(\n",
        "    name=\"cities_to_visit\",\n",
        "    description=\"extract the cities they are going to visit. If there are more than \\\n",
        "    one, put them in square brackets like ['cityone', 'citytwo'].\"\n",
        ")\n",
        "\n",
        "response_schemas = [leave_time_schema, leave_from_schema, cities_to_visit_schema]"
      ],
      "metadata": {
        "id": "ezXn5Q5_JOQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "format_instructions = output_parser.get_format_instructions()"
      ],
      "metadata": {
        "id": "sXa38dN1JOO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(email_template)"
      ],
      "metadata": {
        "id": "Gm-6v_UtJOMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_message = prompt_template.format_messages(email=email_response,format_instructions=format_instructions)"
      ],
      "metadata": {
        "id": "itxrA28tJOKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(format_message)"
      ],
      "metadata": {
        "id": "2EdKjWxeJOH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CQJ78AyJOFV",
        "outputId": "692e8de4-0a2e-4fa3-ac38-f56024922759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_output = output_parser.parse(response.content)"
      ],
      "metadata": {
        "id": "U6QnZ7G3Ln9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(parsed_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-GOyRqEMG3a",
        "outputId": "6110f94b-6342-4131-d494-abe4ee2ab99e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmuNqhTL8tF",
        "outputId": "429cedea-ad2b-4929-bf0e-66b51da8977d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'leave_time': '8:45 pm',\n",
              " 'leave_from': 'Denver, Colorado airport',\n",
              " 'cities_to_visit': ['Amsterdam', 'Brussels']}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_output.get(\"cities_to_visit\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NExCagO4L-02",
        "outputId": "d1081ec8-dbac-4e58-c272-d1db0ca317b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Amsterdam', 'Brussels']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zes2EsQgM7fF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "C9o8qKqon-0Q",
        "dRJ2v0LSnZUQ",
        "-olM9OoyneL-",
        "MCUOF54Sni1n",
        "lEWUt9G7nrIF",
        "brNKJwvmn24L",
        "UUTMiED0n6y8"
      ],
      "authorship_tag": "ABX9TyMo7fFcDs904GSYhSMh/09s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
